{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"MIP_ReLU for fixed parameters.ipynb","provenance":[]}},"cells":[{"cell_type":"code","metadata":{"id":"xbG-SmpHojQB","colab_type":"code","colab":{}},"source":["# -*- coding: utf-8 -*-\n","\"\"\"\n","Created on Thu Apr 23 16:02:33 2020\n","\n","@author: JF LIU\n","\"\"\"\n","#%% data import\n","import torch\n","\n","import numpy as np\n","import random \n","import time\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","#from torchtext import data \n","#from torchtext import datasets\n","\n","import os\n","os.chdir(\"C:/Users/JF LIU/Desktop/DLproject/para\")\n","# BATCH_SIZE = 64\n","#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","# print(device)\n","# train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n","#     (train_data, valid_data, test_data), \n","#     batch_size = BATCH_SIZE, \n","#     device = device)\n","\n","#model\n","\n","class nlp_cnn(nn.Module):\n","    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, \n","                 dropout, pad_idx):\n","        \n","        super().__init__()\n","                \n","        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n","        \n","        self.convs = nn.ModuleList([\n","                                    nn.Conv2d(in_channels = 1, \n","                                              out_channels = n_filters, \n","                                              kernel_size = (fs, embedding_dim)) \n","                                    for fs in filter_sizes\n","                                    ])\n","        \n","        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n","        \n","        self.dropout = nn.Dropout(dropout)\n","        \n","    def forward(self, text):\n","                \n","        #text = [batch size, sent len]\n","        \n","        embedded = self.embedding(text)\n","                \n","        #embedded = [batch size, sent len, emb dim]\n","        \n","        embedded = embedded.unsqueeze(1)\n","\n","        # print(embedded.shape)\n","        \n","        #embedded = [batch size, 1, sent len, emb dim]\n","        \n","        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n","            \n","        #conved_n = [batch size, n_filters, sent len - filter_sizes[n] + 1]\n","                \n","        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n","        \n","        #pooled_n = [batch size, n_filters]\n","        \n","        cat = self.dropout(torch.cat(pooled, dim = 1))\n","\n","        #cat = [batch size, n_filters * len(filter_sizes)]\n","            \n","        return self.fc(cat)\n","\n","\n","INPUT_DIM =  845598 #len(TEXT.vocab)\n","EMBEDDING_DIM = 25\n","N_FILTERS = 25\n","FILTER_SIZES = [3,4]\n","OUTPUT_DIM = 1\n","DROPOUT = 0.5\n","PAD_IDX = 0#TEXT.vocab.stoi[TEXT.pad_token]\n","\n","# model = nlp_cnn(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT, PAD_IDX)\n","\n","# print(model)\n","# pretrained_embeddings = TEXT.vocab.vectors\n","# model.embedding.weight.data.copy_(pretrained_embeddings)\n","\n","\n","# UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n","\n","# model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n","# model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n","\n","model_2 = nlp_cnn(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT, PAD_IDX)\n","\n","model_2.load_state_dict(torch.load('Model_1_State_Dict'))\n","\n","params = []\n","for name, param in model_2.named_parameters():\n","  if param.requires_grad:\n","    params.append((name, param.data.numpy()))\n","#print(params)\n","\n","#X = torch.load(\"Model_1_Intermediates_batch_0_input_embed\")\n","#X.shape\n","#X = np.array(X)\n","\n","#cnn_output = torch.load(\"Model_1_Intermediates_batch_0_fc\")\n","#cnn_output = np.array(cnn_output)\n","\n","weight1 = params[1][1].squeeze(1)\n","bias1 = params[2][1]\n","weight2 = params[3][1].squeeze(1)\n","bias2 = params[4][1]\n","weight_fc = params[5][1]\n","bias_fc = params[6][1]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TkeuoczXojQG","colab_type":"code","colab":{}},"source":["#%% MIP \n","import gurobipy as gp\n","from gurobipy import GRB\n","import numpy as np\n","def minimize_l2(X, W1, b1, W2, b2, weight_fc, bias_fc, cnn_output, sub_rows=10, \\\n","                bound=5, kernel_size=(3,25)):\n","    global m\n","    weight1=W1 \n","    bias1=b1\n","    weight2=W2\n","    bias2=b2\n","    \"\"\"\n","    Parameters\n","    ----------\n","    X : TYPE 2-dimension( height, 25)\n","        node values in cnn \n","    W : TYPE 3-dimension(out_channels, kernel[0], kernel[1])\n","        weights in cnn\n","    b : TYPE 1-dimension(channels, )\n","        bias in cnn\n","    kernel_size : a tuple (3,25)ï¼Œ(4,25) for example, the same as the size in CNN \n","    objective function: minimize manhattan distance between original input X\n","                        and new input Y                   \n","    variables: new input Y\n","    \"\"\"\n","    # code for one batch one channel\n","    #m = gp.Model()\n","    #y = m.addVars(64,X.shape[1],100, name=\"y\")\n","    #X = example\n","    #m = gp.Model()\n","\n","    #choose random rows to adjust\n","    row_list = [i for i in range(X.shape[0])]\n","    row_pick = random.sample(row_list, sub_rows)\n","    row_pick.sort()\n","    row_unchange = list(set(row_list) - set(row_pick))\n","    row_unchange.sort()\n","    #X = X[0,(row_pick),:]\n","\n","    #add variables\n","    y = m.addVars(X.shape[0], X.shape[1], lb=-GRB.INFINITY, name=\"y\")\n","    output = m.addVar(lb=-GRB.INFINITY, name=\"output\")\n","    tmp2 = m.addVar(lb=-GRB.INFINITY, name=\"tmp2\")\n","    m.update()\n","\n","    #create bounds based on a scalar multiple of the original value (paper eq12)\n","    lb = X - bound*abs(X)\n","    ub = X + bound*abs(X)\n","    d = 0\n","\n","    #add constraints. instantiate all the constr. for the places you are changing b.c gurobi needs this to keep track of things.\n","    #can introduce an limiting variable that controls i and j dependent on last plausible variable before padding.\n","    for i in row_pick:\n","        for j in range(X.shape[1]):\n","            v1 = lb[i,j]\n","            v2 = ub[i,j]\n","            if i%2 == 0:\n","                m.addConstr( y[i,j] <= v1 )\n","            else:\n","                m.addConstr( y[i,j] >= v2 )\n","            d = d + (y[i,j] - X[i,j]) * (y[i,j] - X[i,j])\n","    for i in row_unchange:\n","        for j in range(X.shape[1]):\n","            m.addConstr( y[i,j] == X[i,j] )\n","\n","    #eq 8 control difference of the pertubation. min L2 distance. \n","    dist = m.addVar()\n","    m.update()\n","    m.setObjective( dist , GRB.MINIMIZE)\n","    m.addConstr(dist == d)\n","    m.update()\n","    m.setParam(\"NonConvex\", 2)    \n","    #m.setObjective( L2(y, X) , GRB.MINIMIZE)\n","    #m.addGenConstrMax(z[0,2], [y[0,2,1], 0.0], name=\"maxconstr\")\n","\n","    tmp = bias_fc\n","    def conv2vec(y, X, weight, bias, w_fc, b_fc, kernel_size):\n","        \"\"\"\n","        x is the input with size (batch, height, channels=100)\n","        y : the gurobi variables\n","        weight_c, bias_c : weight, bias for each channel\n","        \"\"\"\n","        global m\n","        nonlocal tmp, output\n","        z = m.addVars(X.shape[0], lb=-GRB.INFINITY, vtype=GRB.BINARY, name=\"z\")\n","        a = m.addVars(X.shape[0], lb=0.0, name=\"a\")\n","        c = m.addVars(X.shape[0], lb=0.0, name=\"c\")\n","        #batch_size = X.shape[0]\n","        #kernel_size = (3,50)\n","        length = X.shape[0] - kernel_size[0] + 1 \n","        k_size = kernel_size[0]\n","        bias_c = bias\n","        #bias_c = 0.23\n","        weight_c = weight\n","        #vec = np.zeros((batch_size, length, 1))\n","        #dist = {}\n","        for j in range(length):\n","            # elementwise multipilication for convolutional layer\n","            tp1=bias_c\n","            for k in range(k_size):\n","                for n in range(kernel_size[1]):\n","                    tp1 = tp1 + weight_c[k,n] * y[j+k,n]  \n","                    #print(tp1)\n","                    #m.addGenConstrMax(z[i,j], [tp1, 0.0])\n","                    #print(tp1)\n","                    #a[0,1243]\n","            #eq3 ReLU\n","            m.addConstr(a[j]-c[j] ==  tp1 )\n","            m.addGenConstrIndicator(z[j], True, a[j] <= 0.0)\n","            m.addGenConstrIndicator(z[j], False, c[j] <= 0.0)           \n","        m.update()\n","        u=m.addVar(name=\"u\")\n","        #eq6 FC layer \n","        tmp = tmp + w_fc * u \n","        #eq 5 MaxPool, gurobi custom function.\n","        m.addGenConstrMax(u, [a[i] for i in range(X.shape[0])])\n","        m.update()    \n","        #m.feasRelax()\n","    for i in range(weight1.shape[0]):\n","        conv2vec(y, X, weight1[i], bias1[i], weight_fc[0,i], bias_fc, kernel_size)\n","    for i in range(weight2.shape[0]):\n","        conv2vec(y, X, weight2[i], bias2[i], weight_fc[0,25+i], bias_fc, kernel_size = (4,25))\n","\n","    #tmp = tmp + bias_fc\n","    m.addConstr(tmp2 == tmp)\n","\n","    #eq7 to ensure sigmoid difference for binary, cnn_output is input into sigmoid layer\n","    # if different such as multiclassification or softmax etc.. will need to change this.\n","    m.addConstr( tmp2 * cnn_output <= 0.0 )\n","\n","    m.update()\n","    m.optimize()\n","    if m.status == GRB.INFEASIBLE:\n","        m.feasRelaxS(1, False, False, True)\n","        m.optimize()\n","    vals = m.getVars() \n","    return (vals)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nAWCvHjxgZtX","colab_type":"code","colab":{}},"source":["64x25x25 \n","\n","64x1x1 - upperbound of word embedding (every number is different e.g 1 - 25) - M\n","\n","row_list = [i for i in range(M)]\n","row_pick = random.sample(row_list, sub_rows)\n","row_pick = \n","for i in row_pick:\n","        for j in range(X.shape[1]):\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HZ_Pt5N6ojQJ","colab_type":"code","colab":{},"outputId":"5ec5b44d-d5f8-4039-c2b1-fecd9775d441"},"source":["#%%\n","def extract_y(new_example, X):\n","  \"\"\"\n","  \"\"\"\n","\n","    dim1 = X.shape[0]\n","    dim2 = X.shape[1]\n","    yvalue = [0] * (dim1*dim2)\n","    for i in range(dim1*dim2):\n","        yvalue[i] = new_example[i].X\n","    yvalue = np.reshape(yvalue, (dim1*dim2))\n","    return (yvalue) \n","# \"change the batch_range: a tuple for start and end\"\n","batch_range = (0,101) \n","start = batch_range[0]\n","end = batch_range[1]\n","sub_rows=3 \n","bound=10 \n","for iterations in range(start, end):\n","    input_name1 = \"Model_1_Intermediates_batch_\" + str(iterations) + \"_input_embed\"\n","    input_name2 = \"Model_1_Intermediates_batch_\" + str(iterations) + \"_fc\"\n","    output_name1 = \"Y\" + str(iterations) \n","    output_name2 = \"output\" + str(iterations) \n","    X = torch.load(input_name1)\n","    #X.shape\n","    X = np.array(X)\n","    cnn_output = torch.load(input_name2)\n","    cnn_output = np.array(cnn_output)\n","    tic = time.time()   \n","    new_y = np.zeros((64,25,25))   \n","    new_output = np.zeros((64,1))  \n","    for i in range(64):\n","        example = X[i,:,:]\n","        m = gp.Model()          ##### All parameters to change are sub_rows, bound \n","        m.setParam(\"OutputFlag\", 0)\n","        new_example = minimize_l2(example, weight1, bias1, weight2, bias2, weight_fc, \\\n","                              bias_fc[0], cnn_output[i][0],\\\n","                              sub_rows=sub_rows, bound=bound, kernel_size=(3,25))\n","        new_y[i,:,:] = extract_y(new_example, example).reshape((25,25))\n","        #this should be the minimized variable tmp/output. cost function to understand the relative success of the minimization.\n","        new_output[i,:] = new_example[626].X\n","    \n","    toc = time.time() - tic\n","    print(\"*************time**************\")\n","    print(toc)\n","    print(\"*************product**************\")\n","    #can adjust to select which ones to select.\n","    print(np.sum(new_output*cnn_output<0))\n","    Y = torch.from_numpy(new_y)\n","    Output = torch.from_numpy(new_output)\n","    save_path1 = \"C:/Users/JF LIU/Desktop/DLproject/ad_examples/\" + output_name1\n","    save_path2 = \"C:/Users/JF LIU/Desktop/DLproject/ad_examples/\" + output_name2\n","    torch.save(Y, save_path1)\n","    torch.save(Output, save_path2)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Using license file C:\\Users\\JF LIU\\gurobi.lic\n","Academic license - for non-commercial use only\n","*************time**************\n","295.48266410827637\n","*************product**************\n","56\n","*************time**************\n","291.72149777412415\n","*************product**************\n","51\n","*************time**************\n","287.5970129966736\n","*************product**************\n","49\n","*************time**************\n","284.28090167045593\n","*************product**************\n","44\n","*************time**************\n","281.4733603000641\n","*************product**************\n","55\n","*************time**************\n","284.5601544380188\n","*************product**************\n","48\n","*************time**************\n","282.2263460159302\n","*************product**************\n","50\n","*************time**************\n","281.82152223587036\n","*************product**************\n","51\n","*************time**************\n","278.607075214386\n","*************product**************\n","55\n","*************time**************\n","285.5475881099701\n","*************product**************\n","49\n","*************time**************\n","320.1440327167511\n","*************product**************\n","50\n","*************time**************\n","287.1851680278778\n","*************product**************\n","56\n","*************time**************\n","279.767920255661\n","*************product**************\n","45\n","*************time**************\n","298.4758975505829\n","*************product**************\n","52\n","*************time**************\n","286.0022985935211\n","*************product**************\n","48\n","*************time**************\n","291.1265959739685\n","*************product**************\n","51\n","*************time**************\n","289.621600151062\n","*************product**************\n","53\n","*************time**************\n","283.26960825920105\n","*************product**************\n","46\n","*************time**************\n","289.5867145061493\n","*************product**************\n","49\n","*************time**************\n","289.722350358963\n","*************product**************\n","55\n","*************time**************\n","290.3466806411743\n","*************product**************\n","52\n","*************time**************\n","285.6663062572479\n","*************product**************\n","48\n","*************time**************\n","283.5897288322449\n","*************product**************\n","47\n","*************time**************\n","289.1368703842163\n","*************product**************\n","54\n","*************time**************\n","282.3460063934326\n","*************product**************\n","52\n","*************time**************\n","281.43261456489563\n","*************product**************\n","46\n","*************time**************\n","284.5232775211334\n","*************product**************\n","52\n","*************time**************\n","281.8941957950592\n","*************product**************\n","45\n","*************time**************\n","286.6375505924225\n","*************product**************\n","51\n","*************time**************\n","284.09240341186523\n","*************product**************\n","54\n","*************time**************\n","289.102059841156\n","*************product**************\n","57\n","*************time**************\n","284.03254795074463\n","*************product**************\n","54\n","*************time**************\n","290.2709410190582\n","*************product**************\n","51\n","*************time**************\n","284.64188742637634\n","*************product**************\n","52\n","*************time**************\n","280.9708106517792\n","*************product**************\n","47\n","*************time**************\n","283.39522194862366\n","*************product**************\n","53\n","*************time**************\n","284.1023802757263\n","*************product**************\n","54\n","*************time**************\n","281.21704721450806\n","*************product**************\n","51\n","*************time**************\n","286.41220211982727\n","*************product**************\n","54\n","*************time**************\n","286.8340742588043\n","*************product**************\n","52\n","*************time**************\n","283.1957776546478\n","*************product**************\n","46\n","*************time**************\n","287.9849576950073\n","*************product**************\n","50\n","*************time**************\n","279.245317697525\n","*************product**************\n","51\n","*************time**************\n","282.43782901763916\n","*************product**************\n","44\n","*************time**************\n","286.248592376709\n","*************product**************\n","46\n","*************time**************\n","279.56546211242676\n","*************product**************\n","50\n","*************time**************\n","288.8566462993622\n","*************product**************\n","48\n","*************time**************\n","281.1482045650482\n","*************product**************\n","54\n","*************time**************\n","288.2154996395111\n","*************product**************\n","48\n","*************time**************\n","355.7208287715912\n","*************product**************\n","50\n","*************time**************\n","287.61194682121277\n","*************product**************\n","48\n","*************time**************\n","284.8872318267822\n","*************product**************\n","48\n","*************time**************\n","283.2506093978882\n","*************product**************\n","51\n","*************time**************\n","285.4208035469055\n","*************product**************\n","51\n","*************time**************\n","288.95435643196106\n","*************product**************\n","45\n","*************time**************\n","281.0575189590454\n","*************product**************\n","49\n","*************time**************\n","281.958065032959\n","*************product**************\n","52\n","*************time**************\n","288.2811782360077\n","*************product**************\n","51\n","*************time**************\n","286.88587474823\n","*************product**************\n","41\n","*************time**************\n","281.4893662929535\n","*************product**************\n","41\n","*************time**************\n","288.2423996925354\n","*************product**************\n","53\n","*************time**************\n","9004.568452358246\n","*************product**************\n","50\n","*************time**************\n","286.4330985546112\n","*************product**************\n","50\n","*************time**************\n","283.25766825675964\n","*************product**************\n","49\n","*************time**************\n","287.0425159931183\n","*************product**************\n","52\n","*************time**************\n","316.06962728500366\n","*************product**************\n","55\n","*************time**************\n","306.84591364860535\n","*************product**************\n","53\n","*************time**************\n","303.1658818721771\n","*************product**************\n","58\n","*************time**************\n","305.46330666542053\n","*************product**************\n","56\n","*************time**************\n","301.65703678131104\n","*************product**************\n","53\n","*************time**************\n","303.2006995677948\n","*************product**************\n","57\n","*************time**************\n","311.3426914215088\n","*************product**************\n","55\n","*************time**************\n","315.7024028301239\n","*************product**************\n","48\n","*************time**************\n","344.76597785949707\n","*************product**************\n","53\n","*************time**************\n","312.0113561153412\n","*************product**************\n","51\n","*************time**************\n","307.8879494667053\n","*************product**************\n","57\n","*************time**************\n","294.33001160621643\n","*************product**************\n","50\n","*************time**************\n","297.0170912742615\n","*************product**************\n","48\n","*************time**************\n","310.6668176651001\n","*************product**************\n","49\n","*************time**************\n","302.35254096984863\n","*************product**************\n","50\n","*************time**************\n","308.20964527130127\n","*************product**************\n","44\n","*************time**************\n","309.81250762939453\n","*************product**************\n","51\n","*************time**************\n","317.2274737358093\n","*************product**************\n","49\n","*************time**************\n","315.68250584602356\n","*************product**************\n","53\n","*************time**************\n","333.4453389644623\n","*************product**************\n","52\n","*************time**************\n","319.0715363025665\n","*************product**************\n","46\n","*************time**************\n","321.40061616897583\n","*************product**************\n","53\n","*************time**************\n","318.69719886779785\n","*************product**************\n","54\n","*************time**************\n","309.09179759025574\n","*************product**************\n","54\n","*************time**************\n","306.4465847015381\n","*************product**************\n","51\n","*************time**************\n","312.6285448074341\n","*************product**************\n","51\n","*************time**************\n","303.92458391189575\n"],"name":"stdout"},{"output_type":"stream","text":["*************product**************\n","58\n","*************time**************\n","312.21443462371826\n","*************product**************\n","50\n","*************time**************\n","307.50527358055115\n","*************product**************\n","46\n","*************time**************\n","308.86168789863586\n","*************product**************\n","49\n","*************time**************\n","318.94436526298523\n","*************product**************\n","51\n","*************time**************\n","308.8900487422943\n","*************product**************\n","52\n","*************time**************\n","303.8369688987732\n","*************product**************\n","52\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BaBbwQ_fojQP","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}