{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Model_1_Train.ipynb","provenance":[],"mount_file_id":"195IbsL6Spsgae8mA3QfRLYZNAO3y6NvZ","authorship_tag":"ABX9TyM4+R/fjbHLojlCyTjoqO7I"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"xEtShRBlrU4Y","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":72},"executionInfo":{"status":"ok","timestamp":1588137793344,"user_tz":240,"elapsed":43068,"user":{"displayName":"wilson tang","photoUrl":"","userId":"13100492500124488270"}},"outputId":"d3500e25-0401-41d7-f623-62864c006449"},"source":["import pandas as pd\n","import numpy as np\n","import random \n","import time\n","\n","import re\n","import spacy\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","from torchsummary import summary\n","from torchtext import data \n","from torchtext import datasets\n","from torchtext import vocab\n","\n","#\n","df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/ML: DO /DL_DO_Project_DNN/Data/Sentiment Analysis Dataset.csv', error_bad_lines= False)\n","\n","# df_rev = pd.read_csv('',error_bad_lines = False)\n","\n","# df_rev_fake = pd.read_csv('',error_bad_lines = False)\n","vec = vocab.Vectors('/content/drive/My Drive/Colab Notebooks/ML: DO /DL_DO_Project_DNN/Embeddings/glove.twitter.27B.25d.txt')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["b'Skipping line 8836: expected 4 fields, saw 5\\n'\n","b'Skipping line 535882: expected 4 fields, saw 7\\n'\n","100%|█████████▉| 1193245/1193514 [00:24<00:00, 48484.72it/s]"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"jW8mnvOHxWzc","colab_type":"code","colab":{}},"source":["NLP = spacy.load('en')\n","def tokenizer (comment):\n","  comment = re.sub(\n","      r\"[\\*\\\"“”\\n\\\\…\\+\\-\\/\\=\\(\\)‘•:\\[\\]\\|’\\!;]\", \" \",\n","      str(comment))\n","  comment = re.sub(r\"[ ]+\", \" \", comment)\n","  comment = re.sub(r\"\\!+\", \"!\", comment)\n","  comment = re.sub(r\"\\,+\", \",\", comment)\n","  comment = re.sub(r\"\\?+\", \"?\", comment)\n","  return [x.text for x in NLP.tokenizer(comment) if x.text != \" \"]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Nx8JDvbutwmJ","colab_type":"text"},"source":["## Preprocessing Data (Avoid running repeatedly as it will take awhile on such a big dataset). Check to see if the csv has already been processed"]},{"cell_type":"code","metadata":{"id":"2vA19TyzQf0-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1588138021619,"user_tz":240,"elapsed":204915,"user":{"displayName":"wilson tang","photoUrl":"","userId":"13100492500124488270"}},"outputId":"4af8d94b-f6f3-4448-eaa1-c6efd8f7dde8"},"source":["\n","# print('Calculating Tokenized Length')\n","# #df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/ML: DO /DL_DO_Project_DNN/Data/Sentiment Analysis Dataset.csv', error_bad_lines= False) \n","df['SentimentText_Len'] = df['SentimentText'].apply(tokenizer).apply(len)\n","\n","# df_filt = df[df['SentimentText_Len'] <= 15]\n","# df_filt = df_filt[df_filt['SentimentText_Len'] >= 10]\n","\n","print('Filtering Data and Renaming Columns')\n","df_filt = df[df['SentimentText_Len'] == 25]\n","df_filt.columns = ['ItemID', 'label', 'SentimentSource' ,'text', 'SentimentText_Len']\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Filtering Data and Renaming Columns\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0HNlzfvUhsWl","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1588028352856,"user_tz":240,"elapsed":391,"user":{"displayName":"wilson tang","photoUrl":"","userId":"13100492500124488270"}},"outputId":"c8bd67b1-155b-40a7-fe7c-d513364d8733"},"source":["df.columns"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['ItemID', 'Sentiment', 'SentimentSource', 'SentimentText'], dtype='object')"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"sVtvGIsEhAEH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":698},"executionInfo":{"status":"ok","timestamp":1588138022360,"user_tz":240,"elapsed":375,"user":{"displayName":"wilson tang","photoUrl":"","userId":"13100492500124488270"}},"outputId":"d2be98eb-e42c-42bf-d919-e5a18d78ecb9"},"source":["# #rerun to resample\n","# print('Resampling Data')\n","#df_filt_downsample = df_filt[['text','label']]#.sample(n = 10000)\n","#df_filt_downsample.to_csv('/content/drive/My Drive/Colab Notebooks/ML: DO /DL_DO_Project_DNN/Data/filtered_sentiment_dataset.csv')\n","\n","df.columns = ['ItemID', 'label', 'SentimentSource' ,'text', 'SentimentText_Len']\n","# df[['text','label']].to_csv('/content/drive/My Drive/Colab Notebooks/ML: DO /DL_DO_Project_DNN/Data/all_sentiment_dataset.csv')\n","print(len(df))\n","print(len(df_filt))\n","print(df)\n","df_filt"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1578612\n","41577\n","          ItemID  ...  SentimentText_Len\n","0              1  ...                  8\n","1              2  ...                  7\n","2              3  ...                  6\n","3              4  ...                 32\n","4              5  ...                  9\n","...          ...  ...                ...\n","1578607  1578623  ...                  5\n","1578608  1578624  ...                  5\n","1578609  1578625  ...                  8\n","1578610  1578626  ...                 10\n","1578611  1578627  ...                  4\n","\n","[1578612 rows x 5 columns]\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ItemID</th>\n","      <th>label</th>\n","      <th>SentimentSource</th>\n","      <th>text</th>\n","      <th>SentimentText_Len</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>22</th>\n","      <td>23</td>\n","      <td>1</td>\n","      <td>Sentiment140</td>\n","      <td>You're the only one who can see this cause...</td>\n","      <td>25</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>27</td>\n","      <td>0</td>\n","      <td>Sentiment140</td>\n","      <td>can't be bothered. i wish i could spend the...</td>\n","      <td>25</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>32</td>\n","      <td>0</td>\n","      <td>Sentiment140</td>\n","      <td>i miss you guys too     i think i'm wearing...</td>\n","      <td>25</td>\n","    </tr>\n","    <tr>\n","      <th>117</th>\n","      <td>118</td>\n","      <td>1</td>\n","      <td>Sentiment140</td>\n","      <td>True, highly subjective of me there. Tombre ...</td>\n","      <td>25</td>\n","    </tr>\n","    <tr>\n","      <th>129</th>\n","      <td>130</td>\n","      <td>0</td>\n","      <td>Sentiment140</td>\n","      <td>- You: hi Stranger: HELLO I AM FRANK LAMPARD ...</td>\n","      <td>25</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1578509</th>\n","      <td>1578525</td>\n","      <td>0</td>\n","      <td>Sentiment140</td>\n","      <td>yzabellopez: Â yayayay cant wait, i just wish ...</td>\n","      <td>25</td>\n","    </tr>\n","    <tr>\n","      <th>1578529</th>\n","      <td>1578545</td>\n","      <td>1</td>\n","      <td>Sentiment140</td>\n","      <td>Zaki stood on a big nail today and is resting,...</td>\n","      <td>25</td>\n","    </tr>\n","    <tr>\n","      <th>1578576</th>\n","      <td>1578592</td>\n","      <td>1</td>\n","      <td>Sentiment140</td>\n","      <td>zomg, CLE -&amp;gt; SEA is pretty far it turns out...</td>\n","      <td>25</td>\n","    </tr>\n","    <tr>\n","      <th>1578587</th>\n","      <td>1578603</td>\n","      <td>0</td>\n","      <td>Sentiment140</td>\n","      <td>Zoran lost Croatian Idol!  The difference was ...</td>\n","      <td>25</td>\n","    </tr>\n","    <tr>\n","      <th>1578600</th>\n","      <td>1578616</td>\n","      <td>1</td>\n","      <td>Sentiment140</td>\n","      <td>zzz twitter. good day today. got a lot accompl...</td>\n","      <td>25</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>41577 rows × 5 columns</p>\n","</div>"],"text/plain":["          ItemID  ...  SentimentText_Len\n","22            23  ...                 25\n","26            27  ...                 25\n","31            32  ...                 25\n","117          118  ...                 25\n","129          130  ...                 25\n","...          ...  ...                ...\n","1578509  1578525  ...                 25\n","1578529  1578545  ...                 25\n","1578576  1578592  ...                 25\n","1578587  1578603  ...                 25\n","1578600  1578616  ...                 25\n","\n","[41577 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"v9rv9eS56OS7","colab_type":"code","colab":{}},"source":["# df_filt_downsample.to_csv('/content/drive/My Drive/Colab Notebooks/ML: DO /DL_DO_Project_DNN/Data/filtered_sentiment_dataset.csv')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"F3WeLp4Loy0h","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":126},"executionInfo":{"status":"ok","timestamp":1588138038272,"user_tz":240,"elapsed":286,"user":{"displayName":"wilson tang","photoUrl":"","userId":"13100492500124488270"}},"outputId":"1360b36a-517a-4ad2-f197-ad64011e2842"},"source":["df.dtypes"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ItemID                int64\n","label                 int64\n","SentimentSource      object\n","text                 object\n","SentimentText_Len     int64\n","dtype: object"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"RmsmFOVehXTP","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"y5mfwG-dfKTO","colab_type":"code","colab":{}},"source":["### Load sampled data from csv.\n","TEXT = data.Field(tokenize = tokenizer, batch_first = True) #batch_first required so we dont have to permute the data for input to CNN.\n","\n","LABEL = data.Field(use_vocab = False,sequential = False)\n","#redundant as our labels are strings...\n","\n","dataset = data.TabularDataset(path = '/content/drive/My Drive/Colab Notebooks/ML: DO /DL_DO_Project_DNN/Data/filtered_sentiment_dataset.csv' \n","                              , format = 'csv', fields = [('', None),(\"text\",TEXT), (\"label\",LABEL)], skip_header = True)\n","\n","train_data, test_data, valid_data = dataset.split(split_ratio = [0.6,0.2,0.2])\n","\n","#load entire dataset to build vocab\n","train_data_all = data.TabularDataset(path = '/content/drive/My Drive/Colab Notebooks/ML: DO /DL_DO_Project_DNN/Data/all_sentiment_dataset.csv' \n","                              , format = 'csv', fields = [('', None),(\"text\",TEXT), (\"label\",LABEL)], skip_header = True)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z4WRlJupY7M9","colab_type":"code","colab":{}},"source":["vec = vocab.Vectors('/content/drive/My Drive/Colab Notebooks/ML: DO /DL_DO_Project_DNN/Embeddings/glove.twitter.27B.25d.txt')\n","\n","# Select only the most important 30000 words\n","# MAX_VOCAB_SIZE = 300000\n","\n","# Build vocabulary\n","TEXT.build_vocab(train_data_all, \n","                #  max_size = MAX_VOCAB_SIZE, \n","                 # Load pretrained embeddings\n","                #  vectors = \"glove.6B.50d\", \n","                #  vectors = \"glove.6B.100d\", \n","                #  vectors = \"glove.6B.200d\", \n","                #  vectors = \"glove.6B.300d\", \n","                  # vectors = vec,\n","                 #vectors = \"glove.twitter.27B.25d\",\n","                vectors = vec,\n","                unk_init = torch.Tensor.normal_)\n","LABEL.build_vocab(train_data)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dhL-dZZPBV2P","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"status":"ok","timestamp":1588138400340,"user_tz":240,"elapsed":3698,"user":{"displayName":"wilson tang","photoUrl":"","userId":"13100492500124488270"}},"outputId":"3fd7ba56-136c-4b9e-9077-29462eea49aa"},"source":["print(len(TEXT.vocab))\n","print(len(LABEL.vocab))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["845598\n","3\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iJLfpRTUBeeq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"status":"ok","timestamp":1588027265152,"user_tz":240,"elapsed":340,"user":{"displayName":"wilson tang","photoUrl":"","userId":"13100492500124488270"}},"outputId":"7483ead5-825f-4226-8f8b-88c9da750942"},"source":["LABEL.vocab.stoi"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["defaultdict(<function torchtext.vocab._default_unk_index>,\n","            {'0': 1, '1': 2, '<unk>': 0})"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"XJZr8640MjTF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1588027266985,"user_tz":240,"elapsed":383,"user":{"displayName":"wilson tang","photoUrl":"","userId":"13100492500124488270"}},"outputId":"c9e13b67-ac44-43fc-9517-2631e1b3eb7b"},"source":["BATCH_SIZE = 64\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(device)\n","train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n","    (train_data, valid_data, test_data), \n","    batch_size = BATCH_SIZE, \n","    sort_key = lambda x: len(x.text),\n","    sort_within_batch = False,\n","    device = device)\n","\n","# for batch in train_iterator:\n","#   print(' ')\n","#   print(batch.label.shape)\n","#   print(batch.label)\n","#   print(batch.text.shape)\n","#   print(batch.text)\n","\n","# for batch in valid_iterator:\n","#   print(' ')\n","#   print(batch.label.shape)\n","#   print(batch.label.type())\n","#   print(batch.text.shape)\n","\n","# for batch in test_iterator:\n","#   print(' ')\n","#   print(batch.label.shape)\n","#   print(batch.label.type())\n","#   print(batch.text.shape)\n","\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["cuda\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cGaSZA7bra22","colab_type":"code","colab":{}},"source":["\n","#model\n","class nlp_cnn(nn.Module):\n","    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, \n","                 dropout, pad_idx):\n","        \n","        super().__init__()\n","                \n","        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n","        \n","        self.convs = nn.ModuleList([\n","                                    nn.Conv2d(in_channels = 1, \n","                                              out_channels = n_filters, \n","                                              kernel_size = (fs, embedding_dim)) \n","                                    for fs in filter_sizes\n","                                    ])\n","        \n","        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n","        \n","        self.dropout = nn.Dropout(dropout)\n","        \n","    def forward(self, text):\n","                \n","        #text = [batch size, sent len]\n","        \n","        embedded = self.embedding(text)\n","                \n","        #embedded = [batch size, sent len, emb dim]\n","        \n","        embedded = embedded.unsqueeze(1)\n","\n","        # print(embedded.shape)\n","        \n","        #embedded = [batch size, 1, sent len, emb dim]\n","        \n","        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n","            \n","        #conved_n = [batch size, n_filters, sent len - filter_sizes[n] + 1]\n","                \n","        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n","        \n","        #pooled_n = [batch size, n_filters]\n","        \n","        cat = self.dropout(torch.cat(pooled, dim = 1))\n","\n","        #cat = [batch size, n_filters * len(filter_sizes)]\n","            \n","        return self.fc(cat)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h1b87yzsukUz","colab_type":"code","colab":{}},"source":["def binary_accuracy(preds, y):\n","    \"\"\"\n","    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n","    \"\"\"\n","\n","    #round predictions to the closest integer\n","    rounded_preds = torch.round(torch.sigmoid(preds))\n","    # print(' ')\n","    # print(rounded_preds)\n","    # print(y)\n","    correct = (rounded_preds == y).float() #convert into float for division \n","    acc = correct.sum() / len(correct)\n","    return acc\n","\n","def train(model, iterator, optimizer, criterion):\n","    \n","    epoch_loss = 0\n","    epoch_acc = 0\n","    \n","    model.train()\n","    \n","    for batch in iterator:\n","        \n","        optimizer.zero_grad()\n","        \n","        predictions = model(batch.text).squeeze(1)\n","        \n","        # print(predictions.type())\n","        # print(batch.label.squeeze(1).type())\n","        loss = criterion(predictions, batch.label.float())\n","        \n","        acc = binary_accuracy(predictions, batch.label.float())\n","        \n","        loss.backward()\n","        \n","        optimizer.step()\n","        \n","        epoch_loss += loss.item()\n","        epoch_acc += acc.item()\n","        \n","    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n","\n","\n","def evaluate(model, iterator, criterion):\n","    \n","    epoch_loss = 0\n","    epoch_acc = 0\n","    \n","    model.eval()\n","    \n","    with torch.no_grad():\n","    \n","        for batch in iterator:\n","\n","            predictions = model(batch.text).squeeze(1)\n","            # print(predictions)\n","            # print(batch.label.float())\n","            loss = criterion(predictions, batch.label.float())\n","            \n","            acc = binary_accuracy(predictions, batch.label.float())\n","\n","            epoch_loss += loss.item()\n","            epoch_acc += acc.item()\n","        \n","    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n","\n","\n","def epoch_time(start_time, end_time):\n","    elapsed_time = end_time - start_time\n","    elapsed_mins = int(elapsed_time / 60)\n","    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n","    return elapsed_mins, elapsed_secs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"E6hyjtctrcn0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":181},"executionInfo":{"status":"ok","timestamp":1588027276890,"user_tz":240,"elapsed":542,"user":{"displayName":"wilson tang","photoUrl":"","userId":"13100492500124488270"}},"outputId":"f7f1ccfb-46be-4fec-e864-b86e0c259147"},"source":["INPUT_DIM =  len(TEXT.vocab)\n","EMBEDDING_DIM = 25\n","N_FILTERS = 25\n","FILTER_SIZES = [3,4]\n","OUTPUT_DIM = 1\n","DROPOUT = 0.5\n","PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n","\n","model = nlp_cnn(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT, PAD_IDX)\n","\n","print(model)\n","pretrained_embeddings = TEXT.vocab.vectors\n","model.embedding.weight.data.copy_(pretrained_embeddings)\n","\n","UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n","\n","model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n","model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["nlp_cnn(\n","  (embedding): Embedding(845598, 25, padding_idx=1)\n","  (convs): ModuleList(\n","    (0): Conv2d(1, 25, kernel_size=(3, 25), stride=(1, 1))\n","    (1): Conv2d(1, 25, kernel_size=(4, 25), stride=(1, 1))\n","  )\n","  (fc): Linear(in_features=50, out_features=1, bias=True)\n","  (dropout): Dropout(p=0.5, inplace=False)\n",")\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"raszhiUJuiCw","colab_type":"code","colab":{}},"source":["optimizer = optim.Adam(model.parameters())\n","\n","criterion = nn.BCEWithLogitsLoss()\n","\n","model = model.to(device)\n","criterion = criterion.to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1lpkl5twumli","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":563},"executionInfo":{"status":"ok","timestamp":1588027362072,"user_tz":240,"elapsed":74453,"user":{"displayName":"wilson tang","photoUrl":"","userId":"13100492500124488270"}},"outputId":"df1e269a-b383-4faf-dee5-fee9743a1be0"},"source":["N_EPOCHS = 10\n","best_valid_loss = float('inf')\n","\n","for epoch in range(N_EPOCHS):\n","\n","    start_time = time.time()\n","    \n","    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n","    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n","    \n","    end_time = time.time()\n","\n","    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","    \n","    if valid_loss < best_valid_loss:\n","        best_valid_loss = valid_loss\n","        torch.save(model.state_dict(), '/content/drive/My Drive/Colab Notebooks/ML: DO /DL_DO_Project_DNN/Model_Param/Model_1_State_Dict')\n","    \n","    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n","    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n","    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch: 01 | Epoch Time: 0m 7s\n","\tTrain Loss: 0.672 | Train Acc: 58.30%\n","\t Val. Loss: 0.626 |  Val. Acc: 66.07%\n","Epoch: 02 | Epoch Time: 0m 6s\n","\tTrain Loss: 0.604 | Train Acc: 67.60%\n","\t Val. Loss: 0.577 |  Val. Acc: 70.16%\n","Epoch: 03 | Epoch Time: 0m 6s\n","\tTrain Loss: 0.549 | Train Acc: 72.62%\n","\t Val. Loss: 0.558 |  Val. Acc: 71.79%\n","Epoch: 04 | Epoch Time: 0m 6s\n","\tTrain Loss: 0.497 | Train Acc: 76.71%\n","\t Val. Loss: 0.558 |  Val. Acc: 72.22%\n","Epoch: 05 | Epoch Time: 0m 6s\n","\tTrain Loss: 0.432 | Train Acc: 80.70%\n","\t Val. Loss: 0.573 |  Val. Acc: 71.51%\n","Epoch: 06 | Epoch Time: 0m 6s\n","\tTrain Loss: 0.361 | Train Acc: 85.17%\n","\t Val. Loss: 0.611 |  Val. Acc: 70.58%\n","Epoch: 07 | Epoch Time: 0m 6s\n","\tTrain Loss: 0.281 | Train Acc: 89.20%\n","\t Val. Loss: 0.685 |  Val. Acc: 69.70%\n","Epoch: 08 | Epoch Time: 0m 6s\n","\tTrain Loss: 0.215 | Train Acc: 92.05%\n","\t Val. Loss: 0.766 |  Val. Acc: 68.53%\n","Epoch: 09 | Epoch Time: 0m 6s\n","\tTrain Loss: 0.166 | Train Acc: 94.19%\n","\t Val. Loss: 0.840 |  Val. Acc: 67.91%\n","Epoch: 10 | Epoch Time: 0m 6s\n","\tTrain Loss: 0.128 | Train Acc: 95.50%\n","\t Val. Loss: 0.955 |  Val. Acc: 67.17%\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"okkXXRod8Fm5","colab_type":"text"},"source":["## Saving Model Intermediates "]},{"cell_type":"code","metadata":{"id":"_t8jdtOyV6sD","colab_type":"code","colab":{}},"source":["path = '/content/drive/My Drive/Colab Notebooks/ML: DO /DL_DO_Project_DNN/Model_Param/Model_1_State_Dict'\n","\n","path_data = '/content/drive/My Drive/Colab Notebooks/ML: DO /DL_DO_Project_DNN/Model_Param_2/Model_1_Embedded_Inputs'\n","path_inter = '/content/drive/My Drive/Colab Notebooks/ML: DO /DL_DO_Project_DNN/Model_Param_2/Model_1_Intermediates'\n","path_data_og = '/content/drive/My Drive/Colab Notebooks/ML: DO /DL_DO_Project_DNN/Model_Param_2/Model_1_Word_Inputs'\n","path_labels = '/content/drive/My Drive/Colab Notebooks/ML: DO /DL_DO_Project_DNN/Model_Param_2/Model_1_Labels'\n","path_valid =  '/content/drive/My Drive/Colab Notebooks/ML: DO /DL_DO_Project_DNN/Data_Val_2/Val'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4_N4l2oGOXyV","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1588028430906,"user_tz":240,"elapsed":7867,"user":{"displayName":"wilson tang","photoUrl":"","userId":"13100492500124488270"}},"outputId":"00cb8120-b060-4798-d95b-dd418fe23705"},"source":["## Loading Parameters\n","# set path equal to where the file 'Model_1_State_Dict' is located\n","#path = ''\n","model_2 = nlp_cnn(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT, PAD_IDX)\n","\n","#load model\n","model_2.load_state_dict(torch.load(path))\n","#set to eval\n","model_2.eval()\n","\n","# #store param\n","# params = []\n","# for name, param in model_2.named_parameters():\n","#   if param.requires_grad:\n","#     params.append((name, param.data.numpy()))\n","# # print(params)\n","\n","# torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","#activation = {} \n","batch_number = 0\n","def get_activation(name):\n","    def hook(model, input, output):\n","      #shift to CPU to reduce cuda usage\n","        #activation[name] = output.detach().cpu().numpy()\n","        save_path = path_inter + '_batch_' + str(batch_number) + '_' + name \n","        torch.save(output.detach().cpu(), save_path)\n","        print(batch_number)\n","        print(name)\n","        # print(output.detach().cpu().numpy().shape)\n","    return hook\n","\n","print(model_2)\n","\n","model_2 = model_2.to(device)\n","#register hooks\n","model_2.embedding.register_forward_hook(get_activation('input_embed'))\n","# model_2.convs[0].register_forward_hook(get_activation('conv_0'))\n","# model_2.convs[1].register_forward_hook(get_activation('conv_1'))\n","# model_2.convs[2].register_forward_hook(get_activation('conv_2'))\n","model_2.fc.register_forward_hook(get_activation('fc'))\n","\n","print(model_2)\n","\n","all_activations = []\n","model_2.eval()\n","\n","with torch.no_grad():\n","    batch_number = 0\n","    for batch in train_iterator:\n","\n","        # activation = {}\n","        torch.save(batch.text, path_data_og + '_batch_' + str(batch_number))\n","\n","        predictions = model_2(batch.text).squeeze(1)\n","\n","        # all_activations.append(activation)\n","        # torch.save(activation, path_inter)\n","        \n","        batch_number +=1\n","        loss = criterion(predictions, batch.label.float())\n","\n","        torch.save(batch.label, path_labels + '_batch_' + str(batch_number))\n","            \n","        acc = binary_accuracy(predictions, batch.label.float())\n","        print(binary_accuracy)\n","\n","# for batch in train_iterator:\n","#   # for i in batch.text: \n","#   data.append(batch.text)\n","#   #reset dictionary\n","#   activation = {}\n","#   #run model on 1 data\n","#   model_2(batch.text)\n","#   #store dictionary in a list\n","#   all_activations.append(activation)\n","\n","# x = torch.randn(1, 25)\n","# output = model(x)\n","# print(activation['fc2'])\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["nlp_cnn(\n","  (embedding): Embedding(845598, 25, padding_idx=1)\n","  (convs): ModuleList(\n","    (0): Conv2d(1, 25, kernel_size=(3, 25), stride=(1, 1))\n","    (1): Conv2d(1, 25, kernel_size=(4, 25), stride=(1, 1))\n","  )\n","  (fc): Linear(in_features=50, out_features=1, bias=True)\n","  (dropout): Dropout(p=0.5, inplace=False)\n",")\n","nlp_cnn(\n","  (embedding): Embedding(845598, 25, padding_idx=1)\n","  (convs): ModuleList(\n","    (0): Conv2d(1, 25, kernel_size=(3, 25), stride=(1, 1))\n","    (1): Conv2d(1, 25, kernel_size=(4, 25), stride=(1, 1))\n","  )\n","  (fc): Linear(in_features=50, out_features=1, bias=True)\n","  (dropout): Dropout(p=0.5, inplace=False)\n",")\n","0\n","input_embed\n","0\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","1\n","input_embed\n","1\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","2\n","input_embed\n","2\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","3\n","input_embed\n","3\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","4\n","input_embed\n","4\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","5\n","input_embed\n","5\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","6\n","input_embed\n","6\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","7\n","input_embed\n","7\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","8\n","input_embed\n","8\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","9\n","input_embed\n","9\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","10\n","input_embed\n","10\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","11\n","input_embed\n","11\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","12\n","input_embed\n","12\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","13\n","input_embed\n","13\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","14\n","input_embed\n","14\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","15\n","input_embed\n","15\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","16\n","input_embed\n","16\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","17\n","input_embed\n","17\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","18\n","input_embed\n","18\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","19\n","input_embed\n","19\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","20\n","input_embed\n","20\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","21\n","input_embed\n","21\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","22\n","input_embed\n","22\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","23\n","input_embed\n","23\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","24\n","input_embed\n","24\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","25\n","input_embed\n","25\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","26\n","input_embed\n","26\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","27\n","input_embed\n","27\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","28\n","input_embed\n","28\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","29\n","input_embed\n","29\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","30\n","input_embed\n","30\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","31\n","input_embed\n","31\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","32\n","input_embed\n","32\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","33\n","input_embed\n","33\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","34\n","input_embed\n","34\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","35\n","input_embed\n","35\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","36\n","input_embed\n","36\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","37\n","input_embed\n","37\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","38\n","input_embed\n","38\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","39\n","input_embed\n","39\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","40\n","input_embed\n","40\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","41\n","input_embed\n","41\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","42\n","input_embed\n","42\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","43\n","input_embed\n","43\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","44\n","input_embed\n","44\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","45\n","input_embed\n","45\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","46\n","input_embed\n","46\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","47\n","input_embed\n","47\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","48\n","input_embed\n","48\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","49\n","input_embed\n","49\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","50\n","input_embed\n","50\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","51\n","input_embed\n","51\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","52\n","input_embed\n","52\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","53\n","input_embed\n","53\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","54\n","input_embed\n","54\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","55\n","input_embed\n","55\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","56\n","input_embed\n","56\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","57\n","input_embed\n","57\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","58\n","input_embed\n","58\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","59\n","input_embed\n","59\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","60\n","input_embed\n","60\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","61\n","input_embed\n","61\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","62\n","input_embed\n","62\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","63\n","input_embed\n","63\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","64\n","input_embed\n","64\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","65\n","input_embed\n","65\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","66\n","input_embed\n","66\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","67\n","input_embed\n","67\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","68\n","input_embed\n","68\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","69\n","input_embed\n","69\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","70\n","input_embed\n","70\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","71\n","input_embed\n","71\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","72\n","input_embed\n","72\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","73\n","input_embed\n","73\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","74\n","input_embed\n","74\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","75\n","input_embed\n","75\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","76\n","input_embed\n","76\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","77\n","input_embed\n","77\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","78\n","input_embed\n","78\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","79\n","input_embed\n","79\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","80\n","input_embed\n","80\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","81\n","input_embed\n","81\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","82\n","input_embed\n","82\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","83\n","input_embed\n","83\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","84\n","input_embed\n","84\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","85\n","input_embed\n","85\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","86\n","input_embed\n","86\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","87\n","input_embed\n","87\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","88\n","input_embed\n","88\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","89\n","input_embed\n","89\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","90\n","input_embed\n","90\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","91\n","input_embed\n","91\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","92\n","input_embed\n","92\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","93\n","input_embed\n","93\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","94\n","input_embed\n","94\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","95\n","input_embed\n","95\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","96\n","input_embed\n","96\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","97\n","input_embed\n","97\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","98\n","input_embed\n","98\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","99\n","input_embed\n","99\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","100\n","input_embed\n","100\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","101\n","input_embed\n","101\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","102\n","input_embed\n","102\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","103\n","input_embed\n","103\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","104\n","input_embed\n","104\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","105\n","input_embed\n","105\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","106\n","input_embed\n","106\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","107\n","input_embed\n","107\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","108\n","input_embed\n","108\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","109\n","input_embed\n","109\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","110\n","input_embed\n","110\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","111\n","input_embed\n","111\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","112\n","input_embed\n","112\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","113\n","input_embed\n","113\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","114\n","input_embed\n","114\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","115\n","input_embed\n","115\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","116\n","input_embed\n","116\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","117\n","input_embed\n","117\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","118\n","input_embed\n","118\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","119\n","input_embed\n","119\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","120\n","input_embed\n","120\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","121\n","input_embed\n","121\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","122\n","input_embed\n","122\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","123\n","input_embed\n","123\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","124\n","input_embed\n","124\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","125\n","input_embed\n","125\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","126\n","input_embed\n","126\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","127\n","input_embed\n","127\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","128\n","input_embed\n","128\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","129\n","input_embed\n","129\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","130\n","input_embed\n","130\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","131\n","input_embed\n","131\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","132\n","input_embed\n","132\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","133\n","input_embed\n","133\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","134\n","input_embed\n","134\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","135\n","input_embed\n","135\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","136\n","input_embed\n","136\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","137\n","input_embed\n","137\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","138\n","input_embed\n","138\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","139\n","input_embed\n","139\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","140\n","input_embed\n","140\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","141\n","input_embed\n","141\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","142\n","input_embed\n","142\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","143\n","input_embed\n","143\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","144\n","input_embed\n","144\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","145\n","input_embed\n","145\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","146\n","input_embed\n","146\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","147\n","input_embed\n","147\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","148\n","input_embed\n","148\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","149\n","input_embed\n","149\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","150\n","input_embed\n","150\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","151\n","input_embed\n","151\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","152\n","input_embed\n","152\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","153\n","input_embed\n","153\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","154\n","input_embed\n","154\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","155\n","input_embed\n","155\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","156\n","input_embed\n","156\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","157\n","input_embed\n","157\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","158\n","input_embed\n","158\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","159\n","input_embed\n","159\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","160\n","input_embed\n","160\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","161\n","input_embed\n","161\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","162\n","input_embed\n","162\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","163\n","input_embed\n","163\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","164\n","input_embed\n","164\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","165\n","input_embed\n","165\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","166\n","input_embed\n","166\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","167\n","input_embed\n","167\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","168\n","input_embed\n","168\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","169\n","input_embed\n","169\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","170\n","input_embed\n","170\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","171\n","input_embed\n","171\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","172\n","input_embed\n","172\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","173\n","input_embed\n","173\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","174\n","input_embed\n","174\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","175\n","input_embed\n","175\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","176\n","input_embed\n","176\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","177\n","input_embed\n","177\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","178\n","input_embed\n","178\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","179\n","input_embed\n","179\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","180\n","input_embed\n","180\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","181\n","input_embed\n","181\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","182\n","input_embed\n","182\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","183\n","input_embed\n","183\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","184\n","input_embed\n","184\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","185\n","input_embed\n","185\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","186\n","input_embed\n","186\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","187\n","input_embed\n","187\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","188\n","input_embed\n","188\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","189\n","input_embed\n","189\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","190\n","input_embed\n","190\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","191\n","input_embed\n","191\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","192\n","input_embed\n","192\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","193\n","input_embed\n","193\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","194\n","input_embed\n","194\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","195\n","input_embed\n","195\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","196\n","input_embed\n","196\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","197\n","input_embed\n","197\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","198\n","input_embed\n","198\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","199\n","input_embed\n","199\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","200\n","input_embed\n","200\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","201\n","input_embed\n","201\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","202\n","input_embed\n","202\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","203\n","input_embed\n","203\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","204\n","input_embed\n","204\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","205\n","input_embed\n","205\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","206\n","input_embed\n","206\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","207\n","input_embed\n","207\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","208\n","input_embed\n","208\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","209\n","input_embed\n","209\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","210\n","input_embed\n","210\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","211\n","input_embed\n","211\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","212\n","input_embed\n","212\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","213\n","input_embed\n","213\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","214\n","input_embed\n","214\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","215\n","input_embed\n","215\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","216\n","input_embed\n","216\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","217\n","input_embed\n","217\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","218\n","input_embed\n","218\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","219\n","input_embed\n","219\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","220\n","input_embed\n","220\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","221\n","input_embed\n","221\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","222\n","input_embed\n","222\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","223\n","input_embed\n","223\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","224\n","input_embed\n","224\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","225\n","input_embed\n","225\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","226\n","input_embed\n","226\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","227\n","input_embed\n","227\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","228\n","input_embed\n","228\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","229\n","input_embed\n","229\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","230\n","input_embed\n","230\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","231\n","input_embed\n","231\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","232\n","input_embed\n","232\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","233\n","input_embed\n","233\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","234\n","input_embed\n","234\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","235\n","input_embed\n","235\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","236\n","input_embed\n","236\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","237\n","input_embed\n","237\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","238\n","input_embed\n","238\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","239\n","input_embed\n","239\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","240\n","input_embed\n","240\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","241\n","input_embed\n","241\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","242\n","input_embed\n","242\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","243\n","input_embed\n","243\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","244\n","input_embed\n","244\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","245\n","input_embed\n","245\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","246\n","input_embed\n","246\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","247\n","input_embed\n","247\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","248\n","input_embed\n","248\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","249\n","input_embed\n","249\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","250\n","input_embed\n","250\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","251\n","input_embed\n","251\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","252\n","input_embed\n","252\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","253\n","input_embed\n","253\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","254\n","input_embed\n","254\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","255\n","input_embed\n","255\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","256\n","input_embed\n","256\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","257\n","input_embed\n","257\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","258\n","input_embed\n","258\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","259\n","input_embed\n","259\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","260\n","input_embed\n","260\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","261\n","input_embed\n","261\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","262\n","input_embed\n","262\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","263\n","input_embed\n","263\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","264\n","input_embed\n","264\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","265\n","input_embed\n","265\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","266\n","input_embed\n","266\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","267\n","input_embed\n","267\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","268\n","input_embed\n","268\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","269\n","input_embed\n","269\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","270\n","input_embed\n","270\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","271\n","input_embed\n","271\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","272\n","input_embed\n","272\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","273\n","input_embed\n","273\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","274\n","input_embed\n","274\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","275\n","input_embed\n","275\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","276\n","input_embed\n","276\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","277\n","input_embed\n","277\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","278\n","input_embed\n","278\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","279\n","input_embed\n","279\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","280\n","input_embed\n","280\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","281\n","input_embed\n","281\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","282\n","input_embed\n","282\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","283\n","input_embed\n","283\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","284\n","input_embed\n","284\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","285\n","input_embed\n","285\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","286\n","input_embed\n","286\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","287\n","input_embed\n","287\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","288\n","input_embed\n","288\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","289\n","input_embed\n","289\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","290\n","input_embed\n","290\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","291\n","input_embed\n","291\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","292\n","input_embed\n","292\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","293\n","input_embed\n","293\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","294\n","input_embed\n","294\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","295\n","input_embed\n","295\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","296\n","input_embed\n","296\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","297\n","input_embed\n","297\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","298\n","input_embed\n","298\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","299\n","input_embed\n","299\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","300\n","input_embed\n","300\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","301\n","input_embed\n","301\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","302\n","input_embed\n","302\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","303\n","input_embed\n","303\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","304\n","input_embed\n","304\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","305\n","input_embed\n","305\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","306\n","input_embed\n","306\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","307\n","input_embed\n","307\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","308\n","input_embed\n","308\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","309\n","input_embed\n","309\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","310\n","input_embed\n","310\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","311\n","input_embed\n","311\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","312\n","input_embed\n","312\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","313\n","input_embed\n","313\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","314\n","input_embed\n","314\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","315\n","input_embed\n","315\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","316\n","input_embed\n","316\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","317\n","input_embed\n","317\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","318\n","input_embed\n","318\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","319\n","input_embed\n","319\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","320\n","input_embed\n","320\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","321\n","input_embed\n","321\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","322\n","input_embed\n","322\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","323\n","input_embed\n","323\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","324\n","input_embed\n","324\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","325\n","input_embed\n","325\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","326\n","input_embed\n","326\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","327\n","input_embed\n","327\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","328\n","input_embed\n","328\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","329\n","input_embed\n","329\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","330\n","input_embed\n","330\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","331\n","input_embed\n","331\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","332\n","input_embed\n","332\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","333\n","input_embed\n","333\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","334\n","input_embed\n","334\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","335\n","input_embed\n","335\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","336\n","input_embed\n","336\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","337\n","input_embed\n","337\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","338\n","input_embed\n","338\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","339\n","input_embed\n","339\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","340\n","input_embed\n","340\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","341\n","input_embed\n","341\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","342\n","input_embed\n","342\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","343\n","input_embed\n","343\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","344\n","input_embed\n","344\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","345\n","input_embed\n","345\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","346\n","input_embed\n","346\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","347\n","input_embed\n","347\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","348\n","input_embed\n","348\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","349\n","input_embed\n","349\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","350\n","input_embed\n","350\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","351\n","input_embed\n","351\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","352\n","input_embed\n","352\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","353\n","input_embed\n","353\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","354\n","input_embed\n","354\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","355\n","input_embed\n","355\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","356\n","input_embed\n","356\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","357\n","input_embed\n","357\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","358\n","input_embed\n","358\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","359\n","input_embed\n","359\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","360\n","input_embed\n","360\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","361\n","input_embed\n","361\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","362\n","input_embed\n","362\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","363\n","input_embed\n","363\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","364\n","input_embed\n","364\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","365\n","input_embed\n","365\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","366\n","input_embed\n","366\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","367\n","input_embed\n","367\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","368\n","input_embed\n","368\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","369\n","input_embed\n","369\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","370\n","input_embed\n","370\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","371\n","input_embed\n","371\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","372\n","input_embed\n","372\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","373\n","input_embed\n","373\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","374\n","input_embed\n","374\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","375\n","input_embed\n","375\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","376\n","input_embed\n","376\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","377\n","input_embed\n","377\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","378\n","input_embed\n","378\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","379\n","input_embed\n","379\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","380\n","input_embed\n","380\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","381\n","input_embed\n","381\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","382\n","input_embed\n","382\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","383\n","input_embed\n","383\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","384\n","input_embed\n","384\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","385\n","input_embed\n","385\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","386\n","input_embed\n","386\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","387\n","input_embed\n","387\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","388\n","input_embed\n","388\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n","389\n","input_embed\n","389\n","fc\n","<function binary_accuracy at 0x7f31fa337378>\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cbdY9KTZ502z","colab_type":"code","colab":{}},"source":["batch_number = 0 \n","for batch in valid_iterator:\n","  torch.save(batch.text,path_valid + '_batch_' + str(batch_number))\n","  batch_number +=1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8flErAqbQuAm","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1587433695515,"user_tz":240,"elapsed":772,"user":{"displayName":"wilson tang","photoUrl":"","userId":"13100492500124488270"}},"outputId":"1436e3e2-c132-469d-fba8-33ffb8c05e45"},"source":["#load the torch file to see if it works out.\n","\n","path = '/content/drive/My Drive/Colab Notebooks/ML: DO /Data/Model_1_Intermediates_conv_0'\n","data_conv_0 = torch.load(path)\n","\n","print(data_conv_0.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["torch.Size([64, 100, 859, 1])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oNvTCnobkiVZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1587413026568,"user_tz":240,"elapsed":291,"user":{"displayName":"wilson tang","photoUrl":"","userId":"13100492500124488270"}},"outputId":"646b3302-3d26-48c4-bbc9-233878c239cf"},"source":["batch.text.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([64, 1169])"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"code","metadata":{"id":"MKscD6iLUCpo","colab_type":"code","colab":{}},"source":["print(len(all_activations))\n","print(len(train_data))\n","\n","print(all_activations[0])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8HwBVklA8LZN","colab_type":"text"},"source":["## Testing Sensitivity of GloVE representations."]},{"cell_type":"code","metadata":{"id":"3k6bAiBH8I08","colab_type":"code","colab":{}},"source":["#build lookup dictionary from TEXT.vocab \n","embed_dict = {}\n","for j in TEXT.vocab.stoi:\n","  embed_dict[j] = TEXT.vocab.vectors[TEXT.vocab.stoi[j]]\n","\n","#remove the null and pad possibilities\n","del embed_dict[\"<unk>\"]\n","del embed_dict[\"<pad>\"]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QSc5OrGN8U2D","colab_type":"code","colab":{}},"source":["def sentence_embed(sentence,embed_dict):\n","  sent_mat = []\n","  for i in sentence.split(sep = ' '): \n","    sent_mat.append(embed_dict[i])\n","  \n","  return torch.stack(sent_mat)\n","\n","def rev_word_embed(sent_matrices,embed_dict,metric = 'MSE'):\n","  \"\"\"\n","  Calculates the closest word based on a metric\n","  Inputs:\n","    sent_matrices: 2-d matric representing a sentence of tensors.\n","    embed_dict: dictionary of word: sentence lookups. \n","  \"\"\"\n","  #iterate word in sentence\n","  sentence = ''\n","  for i in sent_matrices:\n","      closest_word = ('test',500)\n","      sentence_mse = []\n","      #find closest based on MSE\n","      for j in embed_dict:\n","        metric_val = np.mean(((embed_dict[j] - i)**2).numpy())\n","        if metric_val < closest_word[1]:\n","\n","          closest_word = (j,metric_val)\n","      sentence_mse.append(closest_word[1])\n","  \n","      sentence += closest_word[0] + ' ' \n","  print(sentence_mse)\n","  return sentence\n","\n","def pt_permute(sentence, sent_mat, val):\n","  \"\"\"\n","  permutes a given tensor matrix representing a sentence at a random point by a random amount.\n","  Inputs: \n","    sentence: original sentence\n","    sent_mat: 2-d tensor matrix\n","    val: range of values\n","  \"\"\"\n","\n","  i = random.randrange(0,sent_mat.shape[0])\n","  j = random.randrange(0,sent_mat.shape[1])\n","\n","  new_sent_mat = sent_mat\n","  new_sent_mat[i][j] += val\n","  return new_sent_mat\n","\n","  print('We permuted the word:' + str(sentence.split(sep = ' ')[i]  + \" by \" + str(val)) )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"baiuQM1V8Xse","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":236},"executionInfo":{"status":"error","timestamp":1587775181521,"user_tz":240,"elapsed":1573,"user":{"displayName":"wilson tang","photoUrl":"","userId":"13100492500124488270"}},"outputId":"c3a4952c-f695-47fa-f4f3-a3669fe0e7c7"},"source":["sentence = 'I like that the movie was about pie'\n","test_sentence = sentence_embed(sentence = sentence,embed_dict = embed_dict)\n","print(sentence)\n","print(test_sentence)\n","for i in range(0,20,1):\n","  print('Permute by ' + str(i))\n","  test_sentence = sentence_embed(sentence = sentence,embed_dict = embed_dict)\n","\n","  test_sentence_permuted = pt_permute(sentence = sentence, sent_mat = test_sentence, val = i)\n","\n","  final_sent = rev_word_embed(test_sentence_permuted, embed_dict = embed_dict)\n","  print(final_sent)"],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-ce29731dcbca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'I like that the movie was about pie'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentence_embed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0membed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_sentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'sentence_embed' is not defined"]}]},{"cell_type":"code","metadata":{"id":"PBcksdcyyEFO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1587760497470,"user_tz":240,"elapsed":1274561,"user":{"displayName":"wilson tang","photoUrl":"","userId":"13100492500124488270"}},"outputId":"bed059bc-5da8-4cdc-dabf-bcb4fec2427b"},"source":["#load MIP data\n","path = \"/content/drive/My Drive/Colab Notebooks/ML: DO /DL_DO_Project_DNN/Data/Y0\"\n","data_mip = torch.load(path)\n","\n","data_in = torch.load(\"/content/drive/My Drive/Colab Notebooks/ML: DO /DL_DO_Project_DNN/Model_Param/Model_1_Intermediates_batch_0_input_embed\")\n","\n","print(type(data))\n","for i in range(0,len(data)):\n","  # print(i)\n","  print(rev_word_embed(sent_matrices = data_in[i], embed_dict = embed_dict, metric = 'MSE'))\n","  print(rev_word_embed(sent_matrices = data_mip[i] ,embed_dict = embed_dict ,metric = 'MSE'))\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["<class 'torch.Tensor'>\n","[0.0060009314]\n","I totally stalked gaga at rove tonight , but security yelled at us to go away they do nt do that for you lol bitches \n","[0.008160587076293725]\n","I totally stalked gaga at rove tonight , but security yelled at us to go away they do nt do that for you lol bitches \n","[0.001817887]\n","I did the only person who really cares about me leave to the army . I one loves me anymore . I hate it . \n","[0.0037542696174383662]\n","I did the only person who really cares about me leave to the army . I one loves me anymore . I hate it . \n","[0.0081332745]\n","I I ohhh I wish I could I have to go to school though which is unlucky because it 's my last week I shame \n","[0.006286405709794657]\n","I I ohhh I wish I could I have to go to school though which is unlucky because it 's my last week I shame \n","[0.0024811395]\n","I I lakers I I last night I m so I they can do it again on I I is the sun sooo ugly out \n","[0.0020512947746822835]\n","I I lakers I I last night I m so I they can do it again on I I is the sun sooo ugly out \n","[0.008064169]\n","I , I am going to bed I enjoy your snake adventures I I if you live to tell the tale , tell it well \n","[0.008462587039581453]\n","I , I am going to bed I enjoy your snake adventures I I if you live to tell the tale , tell it well \n","[0.017193131]\n","I I any normal person that is the subtitle , but to a I it is the title proper and I I is the series \n","[0.016125730705199525]\n","I I any normal person that is the subtitle , but to a I it is the title proper and I I is the series \n","[0.004357557]\n","having a great night with some friends , happy birthday mikey listening to a bunch of drunk people sing journey . I 'm designated driver \n","[0.00314045270229583]\n","having a great night with some friends , happy birthday mikey listening to a bunch of drunk people sing journey . I 'm designated driver \n","[0.004539603]\n","bad news ll my dilf manager is I homosexual . I well i think . you guys i 'm so disappointed . devastated , really \n","[0.005157558151901565]\n","bad news ll my dilf manager is I homosexual . I well i think . you guys i 'm so disappointed . devastated , really \n","[0.0030511657]\n","I I is what my I sister in law calls ~ ' going out , do n't know what time I 'll be back ' \n","[0.0029773236833349486]\n","I I is what my I sister in law calls ~ ' going out , do n't know what time I 'll be back ' \n","[0.0022250114]\n","might be late for church I thankin I for waking me and my loved one 's up this morning p.s . I I 's I \n","[0.0021068147127143596]\n","might be late for church I thankin I for waking me and my loved one 's up this morning p.s . I I 's I \n","[0.001817887]\n","I ok i just saw your I comment . I seasalt must be in your brain . I your husband is a smart man . \n","[0.0037542696174383662]\n","I ok i just saw your I comment . I seasalt must be in your brain . I your husband is a smart man . \n","[0.16579694]\n","I hahha sorrry , ofcourse i still have your I I i ' gon na post hhaa and yul 's retarded version of a lunatic \n","[0.16145131443841151]\n","I hahha sorrry , ofcourse i still have your I I i ' gon na post hhaa and yul 's retarded version of a lunatic \n","[0.001817887]\n","I I of them multiple times too you can tell too , they are so worn out , lmao . i need new ones . \n","[0.0037542696174383662]\n","I I of them multiple times too you can tell too , they are so worn out , lmao . i need new ones . \n","[0.0011868484]\n","i do nt think he assumed how bad i want him there . I would mean the world to me . I wish he understood \n","[0.0019824755333052685]\n","i do nt think he assumed how bad i want him there . I would mean the world to me . I wish he understood \n","[0.012810683]\n","I do n't worry never gon na put anyone in a bin or skip or anything , so safe to come back to the family \n","[0.0131157316347045]\n","I do n't worry never gon na put anyone in a bin or skip or anything , so safe to come back to the family \n","[0.001817887]\n","I haha . i like not making sense on twitter . it is my creative release . not go solve the mystery of life . \n","[0.0037542696174383662]\n","I haha . i like not making sense on twitter . it is my creative release . not go solve the mystery of life . \n","[0.001817887]\n","I I you got your I up and running again I I , I 'm sitting over here calculating the cost of a I . \n","[0.0037542696174383662]\n","I I you got your I up and running again I I , I 'm sitting over here calculating the cost of a I . \n","[0.0026941278]\n","I I thought the I I I I I I contest made I a lock . I , I really expected I or I I \n","[0.0025385184761139447]\n","I I thought the I I I I I I contest made I a lock . I , I really expected I or I I \n","[0.0024940146]\n","I I 'm a big fan of I & amp I know sushi & amp buffet rarely mix well I sushi blog http tinyurl.com I \n","[0.0024184602305707837]\n","I I 'm a big fan of I & amp I know sushi & amp buffet rarely mix well I sushi blog http tinyurl.com I \n","[0.0097043775]\n","I lol if he did hav msn then he wud be talking to meee like I I why wud he bother talking to you ? \n","[0.011495557544330834]\n","I lol if he did hav msn then he wud be talking to meee like I I why wud he bother talking to you ? \n","[0.0034479287]\n","I has many fathers and failure is an orphan . I the investors who invested in I , think they are visionaries , go figure \n","[0.0035523001780865537]\n","I has many fathers and failure is an orphan . I the investors who invested in I , think they are visionaries , go figure \n","[0.0034784433]\n","I sad I I forgot about I & quot I I I I i missed it & amp I could have jst taped it I \n","[0.003402935356717889]\n","I sad I I forgot about I & quot I I I I i missed it & amp I could have jst taped it I \n","[0.0030511657]\n","not in the mood on nothing , nothing at all this strange feeling continuously comes when i 'm not feel ' i 'm home ' \n","[0.0029773236833349486]\n","not in the mood on nothing , nothing at all this strange feeling continuously comes when i 'm not feel ' i 'm home ' \n","[0.010869805]\n","I stay tuned in I as we get all our galz aboard here on twitter add each other and meet your gorgeous shopping sorority sisters \n","[0.011232132598529317]\n","I stay tuned in I as we get all our galz aboard here on twitter add each other and meet your gorgeous shopping sorority sisters \n","[0.0052109705]\n","I n't I I I I I I I I I I I I I I I I I , I I I I I \n","[0.005009061480713661]\n","I n't I I I I I I I I I I I I I I I I I , I I I I I \n","[0.025430983]\n","I looking for a job in I it 's so hard I am gon na end up designing for the homeless at this rate lol \n","[0.027791619541276152]\n","I looking for a job in I it 's so hard I am gon na end up designing for the homeless at this rate lol \n","[0.0033518488]\n","I any sleep go through terrible phases of getting too hot and then not sleeping very sad day just taken my mum to the station \n","[0.002822530500286944]\n","I any sleep go through terrible phases of getting too hot and then not sleeping very sad day just taken my mum to the station \n","[0.004900958]\n","I I I , I haaay i 'm I . and this is how excited i am that school is over I http tinyurl.com I \n","[0.004698917954781131]\n","I I I , I haaay i 'm I . and this is how excited i am that school is over I http tinyurl.com I \n","[0.001817887]\n","I just won a copy of I I on I thanks to I I I and I . I wanted to see that movie . \n","[0.0037542696174383662]\n","I just won a copy of I I on I thanks to I I I and I . I wanted to see that movie . \n","[0.0034784433]\n","I the I I I on I I I i was by I street or something I like I mins from the staples center I \n","[0.003402935356717889]\n","I the I I I on I I I i was by I street or something I like I mins from the staples center I \n","[0.0041933637]\n","I I feel ya I during the winter I kept a scarf and sweater around . I keeping a sweater for summer will probably suffice \n","[0.004409942754643316]\n","I I feel ya I during the winter I kept a scarf and sweater around . I keeping a sweater for summer will probably suffice \n","[0.0017017224]\n","I I I . & quot I 've never been stabbed , but I 'd imagine it 'd be quite I I made my night \n","[0.0028360490667855287]\n","I I I . & quot I 've never been stabbed , but I 'd imagine it 'd be quite I I made my night \n","[0.0046359077]\n","I I I always adores I , really glad its included on the tour . I likes playing here . I ago nobody played here \n","[0.005611068536890698]\n","I I I always adores I , really glad its included on the tour . I likes playing here . I ago nobody played here \n","[0.001817887]\n","I not soon enough I wanted to enjoy my last days here not spend them chained to my desk I well , enough whining . \n","[0.0037542696174383662]\n","I not soon enough I wanted to enjoy my last days here not spend them chained to my desk I well , enough whining . \n","[0.010557816]\n","I yeah I I think its called drunk tweeting I I 've got crazy video from last night I need to post on I I \n","[0.010146603380098596]\n","I yeah I I think its called drunk tweeting I I 've got crazy video from last night I need to post on I I \n","[0.0011909615]\n","I I balancing a conversation with this I am looking down not up that s why the lips are curved an I http I I \n","[0.0011395737021762356]\n","I I balancing a conversation with this I am looking down not up that s why the lips are curved an I http I I \n","[0.00556369]\n","waiting for my mum to pop back from work to take me the hospitals , extraction is getting taken out , dreading it so much \n","[0.0065656793089710775]\n","waiting for my mum to pop back from work to take me the hospitals , extraction is getting taken out , dreading it so much \n","[0.008759242]\n","I hahahha love you too and i can pass one to you on twitter ? if that 'll make you feel better & lt I \n","[0.008259904618541562]\n","I hahahha love you too and i can pass one to you on twitter ? if that 'll make you feel better & lt I \n","[0.0028259815]\n","thinks the I show I and pregnant is a sad show . why do the dads always leave after the baby is born I jerks \n","[0.002708303306468849]\n","thinks the I show I and pregnant is a sad show . why do the dads always leave after the baby is born I jerks \n","[0.0028610034]\n","I that one really did suck . I % of the time I & lt I I I the other I % was this morning \n","[0.0036120512850444982]\n","I that one really did suck . I % of the time I & lt I I I the other I % was this morning \n","[0.001817887]\n","I I did n't charge on my I . I broken I wire . I , at least I got my charger from work . \n","[0.0037542696174383662]\n","I I did n't charge on my I . I broken I wire . I , at least I got my charger from work . \n","[0.017458497]\n","I me just now at school field teaching myself to ride with my new albums . I richmond to bike store guy who suggested grass \n","[0.021131656328570784]\n","I me just now at school field teaching myself to ride with my new albums . I richmond to bike store guy who suggested grass \n","[0.001817887]\n","I . I blood stains out of the carpet . I cats are going to be the death of me . I baby bunny . \n","[0.0037542696174383662]\n","I . I blood stains out of the carpet . I cats are going to be the death of me . I baby bunny . \n","[0.025430983]\n","ok did nt get to see obsessed it was sold out but i got to see the new eminem video what happened to em lol \n","[0.027791619541276152]\n","ok did nt get to see obsessed it was sold out but i got to see the new eminem video what happened to em lol \n","[0.001817887]\n","I I got my dates confused you mean it is n't I yet ? . I I 'll see you in a few months . \n","[0.0037542696174383662]\n","I I got my dates confused you mean it is n't I yet ? . I I 'll see you in a few months . \n","[0.001817887]\n","I time for lunch . I family day . I ya later . I the rest of the day with your family , guys . \n","[0.0037542696174383662]\n","I time for lunch . I family day . I ya later . I the rest of the day with your family , guys . \n","[0.001817887]\n","I I I I the I last weekend then I soon after and just today it hit both boys & amp me . I . \n","[0.0037542696174383662]\n","I I I I the I last weekend then I soon after and just today it hit both boys & amp me . I . \n","[0.0097043775]\n","yo guys . feeling sad now . do n't know why but i 'm so depressed . do you guys ever get those moments ? \n","[0.011495557544330834]\n","yo guys . feeling sad now . do n't know why but i 'm so depressed . do you guys ever get those moments ? \n","[0.0097043775]\n","I hey beautiful can you send me a link s to all your new stuff so we can out it up on I f ? \n","[0.011495557544330834]\n","I hey beautiful can you send me a link s to all your new stuff so we can out it up on I f ? \n","[0.01803627]\n","I the lack of free refills would get to me . I being said , drink on my behalf I got ta stay sober today \n","[0.017981614712201298]\n","I the lack of free refills would get to me . I being said , drink on my behalf I got ta stay sober today \n","[0.002122964]\n","I heart chill I I especially at night I I & quot I little electro , but mostly chill # I ? http I I \n","[0.0020357008585458482]\n","I heart chill I I especially at night I I & quot I little electro , but mostly chill # I ? http I I \n","[0.0002825839]\n","I heey , sorry for the late reply lol . i m great i ca nt waait for the tour to come back on tommy \n","[0.0006643420681092596]\n","I heey , sorry for the late reply lol . i m great i ca nt waait for the tour to come back on tommy \n","[0.0030896433]\n","I I I I 's going to be an I I I can already tell I not even I am and my inbox is clean \n","[0.0029461791326817286]\n","I I I I 's going to be an I I I can already tell I not even I am and my inbox is clean \n","[0.025831928]\n","I haha i just watched the dj I interview with atlanta omfg . that was so funny i was laughing the whole time . haha \n","[0.029248312921254828]\n","I haha i just watched the dj I interview with philly omfg . that was so funny i was laughing the whole time . haha \n","[0.0097043775]\n","I I have no idea how to vote for you . I keep trying to find a link but its hopeless . help I ? \n","[0.011495557544330834]\n","I I have no idea how to vote for you . I keep trying to find a link but its hopeless . help I ? \n","[0.001817887]\n","I everyone I ca n't believe I 'm going to bed at I . I I , I 'm gon na miss I tonight . \n","[0.0037542696174383662]\n","I everyone I ca n't believe I 'm going to bed at I . I I , I 'm gon na miss I tonight . \n","[0.0097043775]\n","I really want a pair of I trainers with the I addon any body want support my weight loss and buy them for me ? \n","[0.011495557544330834]\n","I really want a pair of I trainers with the I addon any body want support my weight loss and buy them for me ? \n","[0.001817887]\n","i ca nt ' sleep . that was a no no taking two naps . man , i 'll probably knock out around three . \n","[0.0037542696174383662]\n","i ca nt ' sleep . that was a no no taking two naps . man , i 'll probably knock out around three . \n","[0.009393065]\n","I i ca nt open it now . something wrong with my laptop nanti lah ill open it hehe . yea tattoo shoud be fine \n","[0.011102655365272574]\n","I i ca nt open it now . something wrong with my laptop nanti lah ill open it hehe . yea tattoo shoud be fine \n","[0.0]\n","I rain heels twittering good time I paparazzi I careful I girls I I I I I I & amp your music I I I \n","[0.0]\n","I rain heels twittering good time I paparazzi I careful I girls I I I I I I & amp your music I I I \n","[0.001817887]\n","I so blessed that my whole family is asleep safely in their rooms and praying for the I I families who are destroying tonight . \n","[0.0037542696174383662]\n","I so blessed that my whole family is asleep safely in their rooms and praying for the I I families who are forcing tonight . \n","[0.0046331324]\n","I I I I take a picture of something starting with the letter j if your cool I sorry , its I http tinyurl.com I \n","[0.004487048576591412]\n","I I I I take a picture of something starting with the letter j if your cool I sorry , its I http tinyurl.com I \n","[0.001817887]\n","I I if u get chance , post pic of I . I . I can send it to my other I in I . \n","[0.0037542696174383662]\n","I I if u get chance , post pic of I . I . I can send it to my other I in I . \n","[0.0064718407]\n","I ready I part with lappy so that it gets the proper treatment it needs from support , clearing all personal stuff I sending it \n","[0.0072538945493558805]\n","I ready I part with lappy so that it gets the proper treatment it needs from support , clearing all personal stuff I sending it \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FYNmVGYjbbAA","colab_type":"code","colab":{}},"source":["embed_dict = {}\n","for j in TEXT.vocab.stoi:\n","  embed_dict[j] = TEXT.vocab.vectors[TEXT.vocab.stoi[j]]\n","\n","word_dict = {value : key for (key, value) in TEXT.vocab.stoi.items()}\n","\n","def sentence_embed(sentence,embed_dict):\n","    sent_mat = []\n","    for i in sentence.split(sep = ' '): \n","        sent_mat.append(embed_dict[i])\n","\n","    return torch.stack(sent_mat)\n","\n","def input_lookup(sent_matrix,embed_dict):\n","    \"\"\"\n","    \n","    \"\"\"\n","    sentence = ''\n","    for i in sent_matrix:\n","        sentence += embed_dict[int(i)] + ' '\n","    return sentence\n","\n","def rev_word_embed(sent_matrices, word_embeds ,embed_dict, ign_unk = True, metric = 'L2'):\n","    \"\"\"\n","    Calculates the closest word based on a metric\n","    Inputs:\n","    sent_matrices: 2-d matric representing a sentence of tensors.\n","    word_embeds: tensor matrix of all possible word embeddings\n","    embed_dict: dictionary of value: word lookups. \n","    \"\"\"\n","    #iterate word in sentence\n","    sentence = ''\n","    for i in sent_matrices:\n","        if metric == 'L1':\n","            if ign_unk:\n","                closest_word = np.argmin(torch.sum(( torch.abs(word_embeds - i.to(\"cpu\") )), axis = 1).numpy()[2:]) + 2\n","            else:\n","                closest_word = np.argmin(torch.sum(( torch.abs(word_embeds - i.to(\"cpu\") )), axis = 1).numpy())\n","        elif metric == 'L2':\n","            if ign_unk:\n","                closest_word = np.argmin(torch.sum(((word_embeds - i.to(\"cpu\"))**2), axis = 1).numpy()[2:]) + 2\n","            else:\n","                closest_word = np.argmin(torch.sum(((word_embeds - i.to(\"cpu\"))**2), axis = 1).numpy())\n","#         elif metric == 'COS':\n","#             if ign_unk:\n","#                 closest_word = np.argmin(torch.sum(((word_embeds - i.to(\"cpu\"))**2), axis = 1).numpy()[2:]) + 2\n","#             else:\n","#                 closest_word = np.argmin(torch.sum(((word_embeds - i.to(\"cpu\"))**2), axis = 1).numpy())\n","        else:\n","            raise NameError('Please pick L1 or L2 norm as metric')\n","            \n","        sentence += (embed_dict[closest_word] + ' ')\n","    return sentence\n","\n","def pt_permute(sentence, sent_mat, val):\n","    \"\"\"\n","    permutes a given tensor matrix representing a sentence at a random point by a random amount.\n","    Inputs: \n","    sentence: original sentence\n","    sent_mat: 2-d tensor matrix\n","    val: range of values\n","    \"\"\"\n","\n","    i = random.randrange(0,sent_mat.shape[0])\n","    j = random.randrange(0,sent_mat.shape[1])\n","\n","    new_sent_mat = sent_mat\n","    new_sent_mat[i][j] += val\n","    return new_sent_mat\n","\n","    print('We permuted the word:' + str(sentence.split(sep = ' ')[i]  + \" by \" + str(val)) )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ghvfS72jba9N","colab_type":"code","colab":{}},"source":["#load MIP data\n","mip_path = \"/content/drive/My Drive/Colab Notebooks/ML: DO /DL_DO_Project_DNN/adversarial_examples/0-100/output0\"\n","# data_mip = torch.load(mip_path)\n","\n","\n","# in_path = r\"C:\\Users\\wilso\\Desktop\\DL_DO_Project\\Model_Param\\Model_1_Word_Inputs_batch_0\"\n","in_path = \"/content/drive/My Drive/Colab Notebooks/ML: DO /DL_DO_Project_DNN/Model_Param\"\n","data_in = torch.load(in_path)"],"execution_count":null,"outputs":[]}]}